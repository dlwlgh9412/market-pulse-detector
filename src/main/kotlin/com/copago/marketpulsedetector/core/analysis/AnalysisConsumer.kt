package com.copago.marketpulsedetector.core.analysis

import com.copago.marketpulsedetector.common.event.CrawledItemEvent
import com.copago.marketpulsedetector.common.extension.logOnAnomaly
import com.copago.marketpulsedetector.common.log.AnomalyLogService
import com.copago.marketpulsedetector.domain.entity.CrawlAnalysisResultEntity
import com.copago.marketpulsedetector.domain.entity.StockInfoEntity
import com.copago.marketpulsedetector.domain.repository.CrawlAnalysisResultRepository
import com.copago.marketpulsedetector.domain.repository.MarketThemeStockMapRepository
import org.slf4j.LoggerFactory
import org.springframework.kafka.annotation.DltHandler
import org.springframework.kafka.annotation.KafkaListener
import org.springframework.kafka.annotation.RetryableTopic
import org.springframework.kafka.retrytopic.DltStrategy
import org.springframework.retry.annotation.Backoff
import org.springframework.stereotype.Component
import org.springframework.transaction.annotation.Transactional

@Component
class AnalysisConsumer(
    private val stockExtractor: StockExtractor,
    private val themeExtractor: ThemeExtractor,
    private val themeStockMapRepository: MarketThemeStockMapRepository,
    private val stockAnalysisRepository: CrawlAnalysisResultRepository,
    private val logService: AnomalyLogService
) {
    private val logger = LoggerFactory.getLogger(javaClass)

    @RetryableTopic(
        attempts = "4",
        backoff = Backoff(delay = 1000, multiplier = 2.0),
        dltStrategy = DltStrategy.FAIL_ON_ERROR
    )
    @KafkaListener(topics = ["crawled.article"], groupId = "market-pulse-analyzer-group")
    @Transactional
    fun analyze(event: CrawledItemEvent) {
        val fullText = "${event.title} ${event.content}"

        // 1. ì§ì ‘ ì–¸ê¸‰ëœ ì¢…ëª© ì¶”ì¶œ
        val directStocks = stockExtractor.extractStocks(fullText)

        // 2. ì–¸ê¸‰ëœ ì •ì¹˜/ì •ì±… í…Œë§ˆ ì¶”ì¶œ
        val themes = themeExtractor.extractThemes(fullText)

        // 3. í…Œë§ˆë¥¼ í†µí•œ ê°„ì ‘ ì¢…ëª© ì¶”ë¡  (Inference)
        val inferredStocks = mutableSetOf<StockInfoEntity>()

        if (themes.isNotEmpty()) {
            logger.info("ğŸ›ï¸ Policy/Theme Detected: ${themes.map { it.themeName }}")

            // ë°œê²¬ëœ í…Œë§ˆì— ë§¤í•‘ëœ ì¢…ëª©ë“¤ì„ ê°€ì ¸ì˜´
            for (theme in themes) {
                val maps = themeStockMapRepository.findAllByThemeId(theme.id!!)
                maps.forEach { map ->
                    runCatching {
                        map.stock.stockName
                        map.stock
                    }.logOnAnomaly(logService = logService,
                        key = "ThemeMap:${map.id}",
                        type = "MISSING_STOCK_INFO",
                        msg = "Theme: ${theme.themeName}"
                    )?.let { inferredStocks.add(it) }
                }
            }
            // (ì„ íƒ) í…Œë§ˆ ë°œê²¬ ì‚¬ì‹¤ ì €ì¥ ë¡œì§ ì¶”ê°€ (CrawlThemeResultEntity)
        }

        // ì¤‘ë³µ ë°©ì§€
        val existingResults = stockAnalysisRepository.findAllByTargetId(event.targetId)
        val existingStockCodes = existingResults.map { it.stock.code }.toSet()

        // 4. ê²°ê³¼ í†µí•© (ì§ì ‘ ì–¸ê¸‰ + ê°„ì ‘ ì¶”ë¡ )
        // ì§ì ‘ ì–¸ê¸‰ì€ ì‹ ë¢°ë„ 1.0, í…Œë§ˆ ì¶”ë¡ ì€ ì‹ ë¢°ë„ 0.7 ì •ë„ë¡œ ì°¨ë“±ì„ ë‘˜ ìˆ˜ ìˆìŒ
        val finalResults = mutableListOf<CrawlAnalysisResultEntity>()

        directStocks.forEach { stock ->
            if (!existingStockCodes.contains(stock.code)) {
                finalResults.add(
                    CrawlAnalysisResultEntity(
                        targetId = event.targetId,
                        stock = stock,
                        confidence = 1.0f
                    )
                )
            }
        }

        // ì´ë¯¸ ì§ì ‘ ì–¸ê¸‰ëœ ì¢…ëª©ì€ ì œì™¸í•˜ê³  ì¶”ê°€
        inferredStocks.forEach { stock ->
            if (!directStocks.contains(stock) && !existingStockCodes.contains(stock.code)) {
                finalResults.add(
                    CrawlAnalysisResultEntity(
                        targetId = event.targetId,
                        stock = stock,
                        confidence = 0.7f, // ê°„ì ‘ ì¶”ë¡ 
                        matchType = "THEME"
                    )
                )
            }
        }

        if (finalResults.isNotEmpty()) {
            stockAnalysisRepository.saveAll(finalResults)
            logger.info("âœ… Saved Analysis: ${finalResults.size} new items (Direct/Inferred).")
        } else {
            logger.info("â„¹ï¸ Analysis skipped (Already extracted or empty).")
        }
    }

    @DltHandler
    fun handleDlt(event: CrawledItemEvent, exception: Exception) {
        logger.error("ğŸ’€ Analysis Completely Failed for URL: ${event.url}", exception)

        // ì‚¬ìš©ìë‹˜ì˜ logServiceë¥¼ í™œìš©í•˜ì—¬ ì‹¤íŒ¨ ê¸°ë¡ ì €ì¥
        logService.record(
            key = "KafkaDLT:${event.targetId}",
            type = "ANALYSIS_FAILURE",
            msg = "Max retry reached. Error: ${exception.message}",
        )
    }
}