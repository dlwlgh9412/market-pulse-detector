package com.copago.marketpulsedetector.core.healing

import com.copago.marketpulsedetector.core.component.HtmlFetcher
import com.copago.marketpulsedetector.core.healing.enums.SelectorObjective
import com.copago.marketpulsedetector.domain.entity.CrawlExtractionRuleChangeHistoryEntity
import com.copago.marketpulsedetector.domain.entity.CrawlExtractionRuleEntity
import com.copago.marketpulsedetector.domain.entity.CrawlTargetEntity
import com.copago.marketpulsedetector.domain.repository.CrawlExtractionRuleChangeHistoryRepository
import com.copago.marketpulsedetector.domain.repository.CrawlExtractionRuleRepository
import com.copago.marketpulsedetector.domain.repository.CrawlPageRuleRepository
import com.copago.marketpulsedetector.domain.repository.CrawlTargetRepository
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import org.jsoup.nodes.Document
import org.jsoup.nodes.Element
import org.slf4j.LoggerFactory
import org.springframework.stereotype.Service
import org.springframework.transaction.annotation.Transactional

@Service
class SelfHealingService(
    private val targetRepository: CrawlTargetRepository,
    private val pageRuleRepository: CrawlPageRuleRepository,
    private val extractionRuleRepository: CrawlExtractionRuleRepository,
    private val historyRepository: CrawlExtractionRuleChangeHistoryRepository,
    private val htmlFetcher: HtmlFetcher,
    private val htmlSanitizer: HtmlSanitizer,
    private val ollamaClient: OllamaClient
) {
    private val logger = LoggerFactory.getLogger(SelfHealingService::class.java)

    /**
     * BROKEN ìƒíƒœì¸ íƒ€ê²Ÿì„ ë¶„ì„í•˜ì—¬ ê·œì¹™ì„ ë³µêµ¬
     */
    @Transactional
    suspend fun healBrokenTask(targetId: Long) = withContext(Dispatchers.IO) {
        val target = targetRepository.findWithMetadataById(targetId)
            ?: throw RuntimeException("Target not found: $targetId")

        logger.info("ğŸš‘ Starting Self-Healing for Target: ${target.targetUrl}")

        try {
            val doc = try {
                htmlFetcher.fetch(target)
            } catch (e: Exception) {
                logger.warn("Could not fetch HTML for healing. Skipping.", e)
                return@withContext
            }

            val sanitizedHtml = htmlSanitizer.sanitize(doc.html())

            var healedCount = when (target.pageType) {
                "LIST" -> healListScope(target, sanitizedHtml, doc)
                "CONTENT" -> healExtractionRules(target, sanitizedHtml, doc)
                else -> 0
            }

            if (healedCount > 0) {
                target.status = "PENDING"
                target.retryCount = 0
                logger.info("âœ… Healed $healedCount rules. Target rescheduled for retry.")
            } else {
                logger.warn("âŒ Failed to heal target. Keeping status as BROKEN.")
            }
            targetRepository.save(target)

        } catch (e: Exception) {
            logger.error("Error during self-healing", e)
        }
    }

    private fun healListScope(target: CrawlTargetEntity, sanitizedHtml: String, doc: Document): Int {
        val pageRule = target.pageRule ?: return 0
        val oldSelector = pageRule.linkSearchScope ?: "body"

        // í˜„ì¬ ì„ íƒì(PageRuleì˜ linkSearchScope)ë¡œ ë§í¬ê°€ ì¡°íšŒë˜ëŠ”ì§€ í™•ì¸ (0ê°œë©´ êµ¬ì¡° ë³€ê²½)
        val currentLinks = doc.select(oldSelector).select("a[href]")
        if (currentLinks.isNotEmpty()) {
            logger.info("â„¹ï¸ LIST Scope seems fine (Found ${currentLinks.size} links). Maybe network issue?")
            return 0
        }

        logger.info("ğŸ”§ Healing LIST Scope for rule: ${pageRule.ruleName}")

        val description = "The main container element that wraps the list of news articles."

        val recommendation = try {
            ollamaClient.recommendSelector(
                htmlSource = sanitizedHtml,
                targetDescription = description,
                objective = SelectorObjective.DISCOVERY_SCOPE
            )
        } catch (e: Exception) {
            logger.error("LLM call failed", e)
            return 0
        }

        val newSelector = recommendation.selector

        if (!newSelector.isNullOrBlank()) {
            val newScope = doc.select(newSelector)
            val linkCount = newScope.select("a[href]").size

            if (linkCount > 0) {
                val updatedPageRule = pageRule.copy(linkSearchScope = newSelector)
                pageRuleRepository.save(updatedPageRule)
                saveHistory(
                    ruleId = pageRule.id!!,
                    targetId = target.id!!,
                    oldVal = oldSelector,
                    newVal = newSelector,
                    reason = "LLM Fix List Scope: Found $linkCount links"
                )
                return 1
            } else {
                logger.warn("âŒ LLM suggested '$newSelector' but still 0 links found.")
            }
        }

        return 0
    }

    private fun healExtractionRules(target: CrawlTargetEntity, rawHtml: String, doc: Document): Int {
        val pageRule = target.pageRule ?: return 0
        val rules = extractionRuleRepository.findAllByPageRule(pageRule)

        var successCount = 0

        for (rule in rules) {
            // 1. í˜„ì¬ ê·œì¹™ìœ¼ë¡œ ì¶”ì¶œ ì‹œë„
            val currentElement = doc.selectFirst(rule.cssSelector)

            // ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜(null or blank) ê²€ì¦ ì‹¤íŒ¨ ì‹œ Brokenìœ¼ë¡œ íŒë‹¨
            val isBroken = !isValidExtraction(currentElement, rule)

            if (isBroken && rule.isRequired) {
                logger.warn("ğŸš¨ Rule Broken: [${rule.jsonKey}]")
                val targetDescription = generateTargetDescription(rule)

                // 2. LLM í˜¸ì¶œ (rawHtmlì„ ë„˜ê¸°ë©´ ë‚´ë¶€ì—ì„œ sanitizeForStructure ìˆ˜í–‰)
                val recommendation = try {
                    ollamaClient.recommendSelector(
                        htmlSource = rawHtml,
                        targetDescription = targetDescription,
                        objective = SelectorObjective.DATA_EXTRACTION
                    )
                } catch (e: Exception) {
                    logger.error("LLM call failed", e)
                    continue
                }

                val newSelector = recommendation.selector

                // 3. [ê²€ì¦ ë¡œì§ ê°•í™”] ìƒˆ ì„ íƒìë¡œ ì¶”ì¶œí•œ ë°ì´í„°ê°€ ìœ íš¨í•œì§€ ê²€ì‚¬
                if (!newSelector.isNullOrBlank()) {
                    val verificationElement = doc.selectFirst(newSelector)

                    if (isValidExtraction(verificationElement, rule)) {
                        // ì„±ê³µ ì‹œ ì—…ë°ì´íŠ¸ ë° ì´ë ¥ ì €ì¥ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
                        val updatedRule = rule.copy(cssSelector = newSelector, status = "ACTIVE")
                        extractionRuleRepository.save(updatedRule)
                        saveHistory(rule.id!!, target.id!!, rule.cssSelector, newSelector, recommendation.reason)

                        logger.info("âœ… Healed [${rule.jsonKey}]! $newSelector")
                        successCount++
                    } else {
                        logger.warn("âŒ LLM suggested '$newSelector' but validation failed.")
                    }
                }
            }
        }
        return successCount
    }

    private fun generateTargetDescription(rule: CrawlExtractionRuleEntity): String {
        val keyName = rule.jsonKey
        return when {
            rule.extractAttributes.isNullOrBlank() ->
                "The specific element containing the text content for '$keyName'."

            rule.extractAttributes?.contains("src") == true ->
                "The <img> tag representing the '$keyName' (focus on src or data-src)."

            rule.extractAttributes?.contains("href") == true ->
                "The <a> tag containing the link URL for '$keyName'."

            else ->
                "The element containing the '${rule.extractAttributes}' attribute for '$keyName'."
        }
    }

    /**
     * [Helper] ë³€ê²½ ì´ë ¥ ì €ì¥
     */
    private fun saveHistory(ruleId: Long, targetId: Long, oldVal: String, newVal: String, reason: String?) {
        historyRepository.save(
            CrawlExtractionRuleChangeHistoryEntity(
                ruleId = ruleId,
                targetId = targetId,
                oldSelector = oldVal,
                newSelector = newVal,
                changeReason = reason ?: "Self Healing",
                isVerified = true
            )
        )
    }

    private fun isValidExtraction(element: Element?, rule: CrawlExtractionRuleEntity): Boolean {
        if (element == null) return false

        // ì†ì„± ì¶”ì¶œì¸ ê²½ìš° (ì˜ˆ: src, href)
        if (!rule.extractAttributes.isNullOrBlank()) {
            val attrValue = element.attr(rule.extractAttributes!!.trim())
            return attrValue.isNotBlank()
            // ì¶”ê°€ ê²€ì¦: ì´ë¯¸ì§€ë¼ë©´ httpë¡œ ì‹œì‘í•˜ëŠ”ì§€ ë“±
            // && (!rule.jsonKey.contains("image") || attrValue.startsWith("http"))
        }

        // í…ìŠ¤íŠ¸ ì¶”ì¶œì¸ ê²½ìš°
        val text = element.text().trim()
        if (text.isBlank()) return false

        // 1. ìµœì†Œ ê¸¸ì´ ê²€ì‚¬ (ë³¸ë¬¸(content)ì¸ë° ë„ˆë¬´ ì§§ìœ¼ë©´ ì˜ì‹¬)
        if (rule.jsonKey == "content" && text.length < 30) {
            return false
        }

        // 2. ê¸ˆì§€ì–´(Blacklist) ê²€ì‚¬
        // ê´‘ê³ , ì €ì‘ê¶Œ ë¬¸êµ¬, ë©”ë‰´ ì´ë¦„ ë“±ì´ ì¡íˆë©´ ì‹¤íŒ¨ë¡œ ê°„ì£¼
        val blackList = listOf("Copyright", "All rights reserved", "ê´‘ê³ ", "ë°°ë„ˆ", "êµ¬ë…", "ë©”ì¸ìœ¼ë¡œ")
        if (blackList.any { text.contains(it, ignoreCase = true) }) {
            return false
        }

        return true
    }
}